{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Part 2: Feedforward network Case study – Multi-layer Perceptron model for predicting heat influx into a home**\n",
    "\n",
    "## 2. Develop feed-forward neural network models (Train few networks)\n",
    "\n",
    "### (i) Gradient descent with constant learning rate and momentum"
   ],
   "id": "22382ffc80fa35d4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T05:42:52.561924Z",
     "start_time": "2024-10-02T05:37:57.831843Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# List of seeds to try\n",
    "SEEDS = [0, 1, 42]\n",
    "\n",
    "# Configuration dictionary\n",
    "config = {\n",
    "    'batch_size': 10,\n",
    "    'epochs': 500,\n",
    "    'patience': 30,\n",
    "    'hidden_neurons': 1  # Starting with 1 hidden neuron as per requirements\n",
    "}\n",
    "\n",
    "# Predefined trials as per assignment requirements\n",
    "trials = {\n",
    "    'A': {'learning_rate': 0.1, 'momentum': 0.1},\n",
    "    'B': {'learning_rate': 0.1, 'momentum': 0.9},\n",
    "    'C': {'learning_rate': 0.5, 'momentum': 0.5},\n",
    "    'D': {'learning_rate': 0.9, 'momentum': 0.1},\n",
    "    'E': {'learning_rate': 0.9, 'momentum': 0.9}\n",
    "}\n",
    "\n",
    "def load_and_preprocess_data(seed):\n",
    "    \"\"\"Load and preprocess the data with the given seed\"\"\"\n",
    "    # Load data\n",
    "    file_path = 'Heat_Influx_insulation_east_south_north.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Define features and target\n",
    "    features = ['Insulation', 'East', 'South', 'North']\n",
    "    target = 'HeatFlux'\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data_normalized = pd.DataFrame(\n",
    "        scaler.fit_transform(data[features + [target]]),\n",
    "        columns=features + [target]\n",
    "    )\n",
    "    \n",
    "    # Split the dataset (60% train, 20% validation, 20% test)\n",
    "    train_data, temp_data = train_test_split(data_normalized, train_size=0.6, random_state=seed)\n",
    "    val_data, test_data = train_test_split(temp_data, train_size=0.5, random_state=seed)\n",
    "    \n",
    "    # Prepare data sets\n",
    "    X_train = train_data[features].values\n",
    "    y_train = train_data[target].values\n",
    "    X_val = val_data[features].values\n",
    "    y_val = val_data[target].values\n",
    "    X_test = test_data[features].values\n",
    "    y_test = test_data[target].values\n",
    "    X_all = data_normalized[features].values\n",
    "    y_all = data_normalized[target].values\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_all, y_all\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_val, y_val, learning_rate, momentum, seed):\n",
    "    \"\"\"Build and train the model with given parameters\"\"\"\n",
    "    K.clear_session()\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Define the model\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "    model = Sequential([\n",
    "        Input(shape=(4,)),\n",
    "        Dense(config['hidden_neurons'], activation='sigmoid', kernel_initializer=initializer),\n",
    "        Dense(1, activation='linear', kernel_initializer=initializer)\n",
    "    ])\n",
    "    \n",
    "    optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config['patience'],\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test, X_all, y_all):\n",
    "    \"\"\"Evaluate the model and return metrics\"\"\"\n",
    "    y_train_pred = model.predict(X_train).flatten()\n",
    "    y_val_pred = model.predict(X_val).flatten()\n",
    "    y_test_pred = model.predict(X_test).flatten()\n",
    "    y_all_pred = model.predict(X_all).flatten()\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE_Trn': mean_squared_error(y_train, y_train_pred),\n",
    "        'MSE_Val': mean_squared_error(y_val, y_val_pred),\n",
    "        'MSE_Test': mean_squared_error(y_test, y_test_pred),\n",
    "        'MSE_All': mean_squared_error(y_all, y_all_pred),\n",
    "        'R2_Trn': r2_score(y_train, y_train_pred),\n",
    "        'R2_Val': r2_score(y_val, y_val_pred),\n",
    "        'R2_Test': r2_score(y_test, y_test_pred),\n",
    "        'R2_All': r2_score(y_all, y_all_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {\n",
    "    'Trial': [], 'Seed': [], 'Learning Rate': [], 'Momentum': [],\n",
    "    'MSE_Trn': [], 'MSE_Val': [], 'MSE_Test': [], 'MSE_All': [],\n",
    "    'R2_Trn': [], 'R2_Val': [], 'R2_Test': [], 'R2_All': []\n",
    "}\n",
    "\n",
    "# Train models for each trial and seed combination\n",
    "for trial, params in trials.items():\n",
    "    best_test_mse = float('inf')\n",
    "    best_seed = None\n",
    "    best_metrics = None\n",
    "    \n",
    "    print(f\"\\nTraining Trial {trial}: Learning Rate = {params['learning_rate']}, Momentum = {params['momentum']}\")\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        print(f\"  Testing seed {seed}\")\n",
    "        \n",
    "        # Load and preprocess data with current seed\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test, X_all, y_all = load_and_preprocess_data(seed)\n",
    "        \n",
    "        # Train model\n",
    "        model, history = build_and_train_model(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            params['learning_rate'], params['momentum'], seed\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = evaluate_model(model, X_train, y_train, X_val, y_val, X_test, y_test, X_all, y_all)\n",
    "        \n",
    "        # Check if this seed produced better results\n",
    "        if metrics['MSE_Test'] < best_test_mse:\n",
    "            best_test_mse = metrics['MSE_Test']\n",
    "            best_seed = seed\n",
    "            best_metrics = metrics\n",
    "    \n",
    "    # Store results for best seed\n",
    "    results['Trial'].append(trial)\n",
    "    results['Seed'].append(best_seed)\n",
    "    results['Learning Rate'].append(params['learning_rate'])\n",
    "    results['Momentum'].append(params['momentum'])\n",
    "    for key, value in best_metrics.items():\n",
    "        results[key].append(value)\n",
    "    \n",
    "    print(f\"  Best seed: {best_seed}, Test MSE: {best_test_mse:.6f}\")\n",
    "\n",
    "# Create and display results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResults Table:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('ffnn_trials_results.csv', index=False)\n",
    "\n",
    "# Print best model based on test MSE\n",
    "best_test_mse = results_df.loc[results_df['MSE_Test'].idxmin()]\n",
    "print(\"\\nBest Model Based on Test Set MSE:\")\n",
    "print(f\"Trial: {best_test_mse['Trial']}\")\n",
    "print(f\"Seed: {best_test_mse['Seed']}\")\n",
    "print(f\"Learning Rate: {best_test_mse['Learning Rate']}\")\n",
    "print(f\"Momentum: {best_test_mse['Momentum']}\")\n",
    "print(f\"Test MSE: {best_test_mse['MSE_Test']:.6f}\")\n",
    "print(f\"Test R²: {best_test_mse['R2_Test']:.6f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Trial A: Learning Rate = 0.1, Momentum = 0.1\n",
      "  Testing seed 0\n",
      "WARNING:tensorflow:From D:\\github_repository\\untitled\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "  Testing seed 1\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "  Testing seed 42\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "  Best seed: 0, Test MSE: 0.004940\n",
      "\n",
      "Training Trial B: Learning Rate = 0.1, Momentum = 0.9\n",
      "  Testing seed 0\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "  Testing seed 1\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "  Testing seed 42\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "  Best seed: 42, Test MSE: 0.005298\n",
      "\n",
      "Training Trial C: Learning Rate = 0.5, Momentum = 0.5\n",
      "  Testing seed 0\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517us/step\n",
      "  Testing seed 1\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 513us/step\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 647us/step\n",
      "  Testing seed 42\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "  Best seed: 0, Test MSE: 0.007966\n",
      "\n",
      "Training Trial D: Learning Rate = 0.9, Momentum = 0.1\n",
      "  Testing seed 0\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "  Testing seed 1\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "  Testing seed 42\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 418us/step\n",
      "  Best seed: 0, Test MSE: 0.005574\n",
      "\n",
      "Training Trial E: Learning Rate = 0.9, Momentum = 0.9\n",
      "  Testing seed 0\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "  Testing seed 1\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0s/step  \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 447us/step\n",
      "  Testing seed 42\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "  Best seed: 1, Test MSE: 0.025809\n",
      "\n",
      "Results Table:\n",
      "Trial  Seed  Learning Rate  Momentum  MSE_Trn  MSE_Val  MSE_Test  MSE_All   R2_Trn   R2_Val  R2_Test   R2_All\n",
      "    A     0            0.1       0.1 0.005192 0.004737  0.004940 0.005050 0.902058 0.920277 0.897111 0.905753\n",
      "    B    42            0.1       0.9 0.004701 0.006336  0.005298 0.005149 0.904214 0.871159 0.924952 0.903917\n",
      "    C     0            0.5       0.5 0.008268 0.008515  0.007966 0.008257 0.844037 0.856686 0.834093 0.845911\n",
      "    D     0            0.9       0.1 0.007462 0.006143  0.005574 0.006819 0.859240 0.896606 0.883905 0.872750\n",
      "    E     1            0.9       0.9 0.022644 0.019712  0.025809 0.022690 0.583413 0.589732 0.543754 0.576563\n",
      "\n",
      "Best Model Based on Test Set MSE:\n",
      "Trial: A\n",
      "Seed: 0\n",
      "Learning Rate: 0.1\n",
      "Momentum: 0.1\n",
      "Test MSE: 0.004940\n",
      "Test R²: 0.897111\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# (a) Analysis of Neural Network Performance with Different Learning Rates and Momentum\n",
    "\n",
    "## Results Table Summary\n",
    "\n",
    "| Trial | Learning Rate | Momentum | Best Seed | Test MSE | Test R² | Overall Performance |\n",
    "|-------|---------------|----------|-----------|----------|---------|---------------------|\n",
    "| A | 0.1 | 0.1 | 0 | 0.004940 | 0.897111 | Best overall |\n",
    "| B | 0.1 | 0.9 | 42 | 0.005298 | 0.924952 | Strong R² values |\n",
    "| C | 0.5 | 0.5 | 0 | 0.007966 | 0.834093 | Moderate performance |\n",
    "| D | 0.9 | 0.1 | 0 | 0.005574 | 0.883905 | Good balance |\n",
    "| E | 0.9 | 0.9 | 1 | 0.025809 | 0.543754 | Poorest performance |\n",
    "\n",
    "## Analysis of Results\n",
    "\n",
    "**Best Performing Model (Trial A)**\n",
    "   - Learning Rate: 0.1\n",
    "   - Momentum: 0.1\n",
    "   - Performance:\n",
    "     * Consistently low MSE across all datasets (Train: 0.005192, Val: 0.004737, Test: 0.004940)\n",
    "     * High R² values (Train: 0.902058, Val: 0.920277, Test: 0.897111)\n",
    "   - This combination suggests that a lower learning rate with lower momentum provides stable and effective training."
   ],
   "id": "cd146bb0a3246c19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
